{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01ebae68",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98f4b2be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x149a4d950>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "torch.manual_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f2fc441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f11971",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b019246f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arjunsharma/development/s25-fermilab-research/venv/lib/python3.12/site-packages/coffea/nanoevents/schemas/fcc.py:5: FutureWarning: In version 2025.1.0 (target date: 2024-12-31 11:59:59-06:00), this will be an error.\n",
      "To raise these warnings as errors (and get stack traces to find out where they're called), run\n",
      "    import warnings\n",
      "    warnings.filterwarnings(\"error\", module=\"coffea.*\")\n",
      "after the first `import coffea` or use `@pytest.mark.filterwarnings(\"error:::coffea.*\")` in pytest.\n",
      "Issue: coffea.nanoevents.methods.vector will be removed and replaced with scikit-hep vector. Nanoevents schemas internal to coffea will be migrated. Otherwise please consider using that package!.\n",
      "  from coffea.nanoevents.methods import vector\n"
     ]
    }
   ],
   "source": [
    "from jetnet.datasets import JetNet\n",
    "from jetnet.datasets.normalisations import FeaturewiseLinearBounded, FeaturewiseLinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03324810",
   "metadata": {},
   "outputs": [],
   "source": [
    "MASK = True\n",
    "NUM_PARTICLES = 30\n",
    "TRAIN_SPLIT = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc6c187d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "feature_maxes = JetNet.fpnd_norm.feature_maxes\n",
    "if MASK:\n",
    "    feature_maxes = feature_maxes + [1]\n",
    "# particle_normalizer = FeaturewiseLinearBounded(\n",
    "#     feature_norms=1.0,\n",
    "#     feature_shifts=[0.0, 0.0, -0.5, -0.5] if MASK else [0.0, 0.0, -0.5],\n",
    "#     feature_maxes=feature_maxes, # Max pre-scaling values of each feature\n",
    "# )\n",
    "\n",
    "FeaturewiseLinear(feature_scales=(1/NUM_PARTICLES))\n",
    "\n",
    "data_args = {\n",
    "    # Gluons, light quarks, and top quarks\n",
    "    \"jet_type\": [\"g\", \"q\", \"t\"],\n",
    "    \"data_dir\": \"datasets/jetnet\",\n",
    "    \"num_particles\": NUM_PARTICLES,\n",
    "    \"particle_features\": (\n",
    "        JetNet.ALL_PARTICLE_FEATURES if MASK else JetNet.ALL_PARTICLE_FEATURES[:-1]\n",
    "    ),\n",
    "    # The order of the list is preserved in the retrieved data\n",
    "    \"jet_features\": [\"eta\", \"pt\", \"mass\", \"num_particles\", \"type\"],\n",
    "    # \"particle_normalisation\": particle_normalizer,\n",
    "    \"split_fraction\": [TRAIN_SPLIT, 1 - TRAIN_SPLIT, 0],\n",
    "    \"download\": True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99bfdbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "X_train = JetNet(**data_args, split=\"train\")\n",
    "X_test = JetNet(**data_args, split=\"valid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c351de38",
   "metadata": {},
   "source": [
    "`X_train` consists of 368113 jets; each of which is represented as a tuple with 2 elements:\n",
    "1. A shape `30 x 4` tensor representing each of the particles in the jet, where the features are in the order of ['etarel', 'phirel', 'ptrel', 'mask']\n",
    "2. A length `5` tensor consisting of jet features [\"eta\", \"pt\", \"mass\", \"num_particles\", \"type\"],"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e43a05",
   "metadata": {},
   "source": [
    "### Cleaning\n",
    "\n",
    "We convert the particles from relative polar coordinates to absolute Cartesian coordinates. To do this, we use the JetNet `relEtaPhiPt_to_cartesian` utility function, which takes in two parameters:\n",
    "1. Particle features, where the last axis is $\\eta^\\text{rel}, phi^\\text{rel}, p_\\text{T}^\\text{rel}$\n",
    "2. Jet features, where the last axis is $\\eta, \\phi, p_\\text{T}, E/c$\n",
    "\n",
    "$E/c$ is equivalent to jet mass. Values for the azimuthal angle $\\phi$ are not provided for jets in the dataset due to the azimuthal symmetry of the collider system. We therefore provide random $\\phi$ values for the jets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1da9ddf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetnet.utils import EtaPhiPtE_to_cartesian\n",
    "\n",
    "def transform_rel_particle_coordinates_to_cartesian(X):\n",
    "    \"\"\"\n",
    "    Transforms relative particle coordinates to absolute Cartesian coordinates using the JetNet relEtaPhiPt_to_cartesian utility function\n",
    "\n",
    "    Requires X to be a list of length N_jets where each item is a tuple (particle_features, jet_features)\n",
    "    where particle_features is of shape (n_particles, n_particle_features)\n",
    "    and jet_features is of length n_jet_features\n",
    "\n",
    "    Particle features need to start as etarel, phirel, ptrel\n",
    "    Jet features need to start as eta, pt, mass\n",
    "\n",
    "    The function generates random phi-values for jets taking into account the azimuthal symmetry of the collider\n",
    "    \"\"\"\n",
    "\n",
    "    particle_polarrel_features = X[:][0][:, :, :3]\n",
    "    \n",
    "    # Phi has to be the second column for the JetNet utility function\n",
    "    jet_eta = (X[:][1][:, 0]).unsqueeze(1)\n",
    "    jet_phi_vals = (2 * torch.pi) * torch.rand(len(X)).unsqueeze(1)\n",
    "    jet_pt_ec = X[:][1][:, 1:3]\n",
    "    jet_features = torch.concat([jet_eta, jet_phi_vals, jet_pt_ec], dim=-1)\n",
    "\n",
    "    # Because of issues with the JetNet utility implementation, we do the conversion ourselves\n",
    "    eta_rel, phi_rel, pt_rel = torch.unbind(particle_polarrel_features, axis=-1)\n",
    "    Eta, Phi, Pt, _ = torch.unbind(jet_features, axis=-1)\n",
    "\n",
    "    pt = pt_rel * Pt.unsqueeze(1)\n",
    "    eta = eta_rel + Eta.unsqueeze(1)\n",
    "    phi = phi_rel + Phi.unsqueeze(1)\n",
    "    p0 = pt * torch.cosh(eta)\n",
    "\n",
    "    stacked = torch.stack([eta, phi, pt, p0], axis=-1)\n",
    "    return EtaPhiPtE_to_cartesian(stacked)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d750bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([368113, 30, 4])\n",
      "torch.Size([157763, 30, 4])\n"
     ]
    }
   ],
   "source": [
    "X_train_particle_transformed = transform_rel_particle_coordinates_to_cartesian(X_train)\n",
    "X_test_particle_transformed = transform_rel_particle_coordinates_to_cartesian(X_test)\n",
    "\n",
    "print(X_train_particle_transformed.shape)\n",
    "print(X_test_particle_transformed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d117c3e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:20: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<>:20: SyntaxWarning: invalid escape sequence '\\p'\n",
      "/var/folders/nf/5j1mvt3s2xxg28f4qcpqlhx40000gn/T/ipykernel_71985/3367453038.py:20: SyntaxWarning: invalid escape sequence '\\p'\n",
      "  ''' `\\psi(p) = Sgn(p) \\cdot \\log(|p| + 1)`\n"
     ]
    }
   ],
   "source": [
    "# Sourced from LorentzNet\n",
    "\n",
    "def normsq4(p):\n",
    "    r''' Minkowski square norm\n",
    "         `\\|p\\|^2 = p[0]^2-p[1]^2-p[2]^2-p[3]^2`\n",
    "    ''' \n",
    "    psq = torch.pow(p, 2)\n",
    "\n",
    "    # 2t^2 - (t^2 + x^2 + y^2 + z^2)\n",
    "    return 2 * psq[..., 0] - psq.sum(dim=-1)\n",
    "    \n",
    "def dotsq4(p,q):\n",
    "    r''' Minkowski inner product\n",
    "         `<p,q> = p[0]q[0]-p[1]q[1]-p[2]q[2]-p[3]q[3]`\n",
    "    '''\n",
    "    psq = p*q\n",
    "    return 2 * psq[..., 0] - psq.sum(dim=-1)\n",
    "    \n",
    "def psi(p):\n",
    "    ''' `\\psi(p) = Sgn(p) \\cdot \\log(|p| + 1)`\n",
    "    '''\n",
    "    return torch.sign(p) * torch.log(torch.abs(p) + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c831d9eb",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744452ad",
   "metadata": {},
   "source": [
    "### Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e72e26",
   "metadata": {},
   "source": [
    "For testing, we design a simple message-passing Lorentz equivariant network based on LorentzNet\n",
    "\n",
    "The inputs to each layer are the particle features $x_i$ for $x = 1 \\dots N$, where $N$ is the number of particles (30). The message $m_{ij}^l$ between particles $i$ and $j$ in the $l$-th layuer is\n",
    "$$\n",
    "m^l_{ij} = \\phi_e(\\psi(||x_i^l - x_j^l||)), \\psi(<x_i^l, x_j^l>))\\\\\n",
    "m^l_{ij} = \\phi_m(m^l_{ij}) m^l_{ij}\n",
    "$$\n",
    "\n",
    "where $\\phi_e$ is a neural network, $\\psi(\\cdot) = \\text{sgn} \\log (|\\cdot| + 1)$, $|| \\cdot || $ is the Minkowski norm, and $<\\cdot, \\cdot>$ is the Minkowski inner product\n",
    "\n",
    "The updated velocity after the $l$-th step is\n",
    "$$\n",
    "x_i^{l+1} = x_i^l + c \\sum\\limits_{j=1}^N \\phi_x(m_{ij}, t') \\cdot |x_j^l - x_i^l|\n",
    "$$\n",
    "\n",
    "where $\\phi_x(m_{ij})$ is a scalar, preserving lorentz equivariance; and $t'$ is the time embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fb48b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minkowski norm and inner product\n",
    "N_EDGE_FEATURES = 2\n",
    "from torch import nn\n",
    "\n",
    "def minkowski_features(x):\n",
    "    x_i = x.unsqueeze(-2) # second-last dimension - N\n",
    "    x_j = x.unsqueeze(-3) # third-last dimension - B\n",
    "    x_diffs = x_i - x_j # (batch_size, n_particles, n_particles, n_features)\n",
    "\n",
    "    norms = normsq4(x_diffs)\n",
    "    dots = dotsq4(x_i, x_j)\n",
    "    norms, dots = psi(norms), psi(dots)\n",
    "    return norms, dots, x_diffs\n",
    "\n",
    "class FMLorentzLayer(nn.Module):\n",
    "    def __init__(self,n_hidden, \n",
    "                 dropout = 0., c_weight=1.0, last_layer=False):\n",
    "        super(FMLorentzLayer, self).__init__()\n",
    "\n",
    "        self.c_weight = c_weight\n",
    "\n",
    "        self.time_embed = nn.Sequential(\n",
    "            nn.Linear(1, n_hidden),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "        )\n",
    "\n",
    "        self.phi_e = nn.Sequential(\n",
    "            nn.Linear(N_EDGE_FEATURES, n_hidden, bias=False),\n",
    "            nn.LayerNorm(n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        layer = nn.Linear(n_hidden, 1, bias=False)\n",
    "        torch.nn.init.xavier_uniform_(layer.weight, gain=0.001)\n",
    "        self.phi_x = nn.Sequential(\n",
    "            #  Message + time -> Embedding\n",
    "            nn.Linear(n_hidden * 2, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            layer)\n",
    "\n",
    "        self.phi_m = nn.Sequential(\n",
    "            nn.Linear(n_hidden, 1),\n",
    "            nn.Sigmoid())\n",
    "    \n",
    "    \n",
    "    def message_passing(self, norms, dots, diffs):\n",
    "        inp = torch.stack([norms, dots], dim=-1)  # Concatenate along feature dimension\n",
    "        # print(f\"{inp.shape=}\")\n",
    "        out = self.phi_e(inp)\n",
    "        # print(f\"phi_e(norms, dots) = {out.shape}\")\n",
    "        out = out * self.phi_m(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "    def forward(self, x_t: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        time_embed = self.time_embed(t.unsqueeze(-1))\n",
    "\n",
    "        norms, dots, diffs = minkowski_features(x_t)\n",
    "        messages = self.message_passing(norms, dots, diffs)\n",
    "\n",
    "        batch_size, n_particles, _, n_hidden = messages.shape\n",
    "        t_broadcast = time_embed.view(batch_size, 1, 1, -1).expand(-1, n_particles, n_particles, -1)\n",
    "\n",
    "        # Concatenate messages with time\n",
    "        messages_with_time = torch.cat([messages, t_broadcast], dim=-1)\n",
    "        velocity_magnitude = self.phi_x(messages_with_time)\n",
    "        velocity = velocity_magnitude * diffs\n",
    "        velocity = torch.mean(velocity, dim=-2)\n",
    "        \n",
    "        return velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09e148c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LorentzFMNet(nn.Module):\n",
    "    def __init__(self, n_hidden, n_layers, dropout=0., c_weight=1.0):\n",
    "        super(LorentzFMNet, self).__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            FMLorentzLayer(n_hidden, dropout=dropout, c_weight=c_weight)\n",
    "            for _ in range(n_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x_t: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        for layer in self.layers:\n",
    "            vel = layer(x_t, t)\n",
    "        return vel\n",
    "    \n",
    "    def step(self, x_t: torch.Tensor, t_start: torch.Tensor, t_end: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Calculate the probability density at a particular time step\n",
    "        \"\"\"\n",
    "        # Reshape t_start to be a column vector and expand to match the batch size of x_t\n",
    "        t_start = t_start.view(1, 1).expand(x_t.shape[0], 1)\n",
    "\n",
    "        # Translate x_t by the expected midpoint velocity between t_start and t_end\n",
    "        start_vel = self.forward(x_t=x_t, t=t_start)\n",
    "        midpoint_x = x_t + (start_vel * (t_end - t_start) / 2)\n",
    "        midpoint_vel = self.forward(x_t=midpoint_x, t=t_start + (t_end - t_start) / 2)\n",
    "\n",
    "        return x_t + (t_end - t_start) * midpoint_vel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b26bff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LorentzFMNet(\n",
      "  (layers): ModuleList(\n",
      "    (0-11): 12 x FMLorentzLayer(\n",
      "      (time_embed): Sequential(\n",
      "        (0): Linear(in_features=1, out_features=64, bias=True)\n",
      "        (1): SiLU()\n",
      "        (2): Linear(in_features=64, out_features=64, bias=True)\n",
      "      )\n",
      "      (phi_e): Sequential(\n",
      "        (0): Linear(in_features=2, out_features=64, bias=False)\n",
      "        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        (2): ReLU()\n",
      "        (3): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (4): ReLU()\n",
      "      )\n",
      "      (phi_x): Sequential(\n",
      "        (0): Linear(in_features=128, out_features=64, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): Linear(in_features=64, out_features=1, bias=False)\n",
      "      )\n",
      "      (phi_m): Sequential(\n",
      "        (0): Linear(in_features=64, out_features=1, bias=True)\n",
      "        (1): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = LorentzFMNet(n_hidden=64, n_layers=12, dropout=0.1, c_weight=1.0).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131a4a8d",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d76ccf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 30, 4])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time = torch.tensor([0.1, 0.5], device=device)  # Example time input\n",
    "x = X_train_particle_transformed[:2].to(device)  # Move to the same device as the model\n",
    "output = model(x, time)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e12ea09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BATCH_SIZE = 128\n",
    "X_train_loaded = DataLoader(X_train_particle_transformed, shuffle=True, batch_size=BATCH_SIZE, pin_memory=True)\n",
    "X_test_loaded = DataLoader(X_test_particle_transformed, shuffle=False, batch_size=BATCH_SIZE, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6745e904",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[50]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     19\u001b[39m     loss.backward()\n\u001b[32m     20\u001b[39m     optimizer.step()\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m     epoch_loss.append(\u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     24\u001b[39m losses.append(np.mean(epoch_loss))\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m epoch % \u001b[32m10\u001b[39m == \u001b[32m0\u001b[39m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "losses = []\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    epoch_loss = []\n",
    "\n",
    "    for i, data in enumerate(X_train_loaded):\n",
    "        x_0 = torch.randn_like(data).to(device)\n",
    "        x_1 = data.to(device)\n",
    "\n",
    "        t = torch.rand(x_0.shape[0], device=device).view(-1, 1, 1)  # Reshape t to match the expected input shape\n",
    "        x_t = (1 - t) * x_0 + t * x_1  # Linear interpolation\n",
    "        dx_t = x_1 - x_0\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss = nn.MSELoss()(model(x_t, t), dx_t)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss.append(loss.item())\n",
    "\n",
    "    losses.append(np.mean(epoch_loss))\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {losses[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab2d149",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
